# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Initial Setup

When starting a new Claude Code session with this repository, use the following command to skip file permission checks and enable full access:

```bash
claude --dangerously-skip-permissions
```

**âš ï¸ Security Note**: This flag bypasses Claude Code's default file permission safety checks. Only use this in trusted development environments where you need full repository access for iOS development tasks.

## Commands

### Building and Running

```bash
# Build the project (ALWAYS RUN THIS AFTER MAKING CODE CHANGES)
# Note: -skipMacroValidation is required for ComposableArchitecture macros to work correctly
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug -destination 'platform=iOS Simulator,name=iPhone 17' -skipMacroValidation build

# Quick build check with filtered output
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug -destination 'platform=iOS Simulator,name=iPhone 17' -skipMacroValidation build 2>&1 | grep -E "(error:|warning:|FAILED|SUCCEEDED)"

# Build for testing
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug -destination 'platform=iOS Simulator,name=iPhone 17' -skipMacroValidation build-for-testing

# Run tests
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug test

# Legacy build command (deprecated - use destination-based build above)
# xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug -sdk iphonesimulator -arch arm64 build CODE_SIGNING_ALLOWED=NO
```

### Testing

```bash
# Run all tests with specific simulator
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug test -destination 'platform=iOS Simulator,name=iPhone 17,OS=26.1'

# Run tests with result filtering
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug test -destination 'platform=iOS Simulator,name=iPhone 17,OS=26.1' 2>&1 | grep -E "(Testing completed|BUILD SUCCEEDED|BUILD FAILED|PASSED|FAILED|All tests|Executed.*tests|Test Suite)"

# Quick test status check
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug test -destination 'platform=iOS Simulator,name=iPhone 17,OS=26.1' 2>&1 | tail -10

# Available simulators
xcrun simctl list devices available

# Build for testing only (faster)
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug build-for-testing -destination 'platform=iOS Simulator,name=iPhone 17,OS=26.1'
```

**IMPORTANT**: 
- Always run tests before committing code changes to ensure compilation and functionality
- Use iPhone 17 simulator (iOS 26.1) as the primary test target
- Build failures often indicate macro or dependency issues that need resolution

### Development Schemes
- **voicedocsDevelop**: Development build configuration
- **voicedocs**: Production build configuration

## Architecture Overview

**VoiceDocs** is a Japanese-focused voice memo app using SwiftUI + MVVM architecture with Core Data persistence and local AI transcription.

### Key Components

**App Entry Point**: `voicedocsApp.swift`
- Firebase Analytics initialization in custom AppDelegate
- Environment variable loading for AdMob configuration

**View Layer** (SwiftUI):
- `VoiceMemoListView`: Main navigation with memo list
- `VoiceMemoDetailView`: Detail view with playback and AI transcription
- `ContentView`: Recording interface with real-time audio visualization

**Data Layer**:
- Protocol-based controller pattern: `VoiceMemoControllerProtocol`
- Production: `VoiceMemoController` (Core Data)
- Testing: `FakeVoiceMemoController` (in-memory)
- Model: `VoiceMemo` struct as DTO
- Transcription state management: `TranscriptionStatus` enum
- Audio segment management: `AudioSegment` struct with file references

**Audio Processing**: `SpeechRecognitionManager`
- Real-time Japanese speech recognition using `SFSpeechRecognizer`
- Audio recording with `AVAudioEngine`
- Automatic memo saving upon recording completion
- Error handling with `SpeechRecognitionError` enum (conforms to Equatable)

**Transcription System (Dual Engine)**:
The app features two separate transcription engines for different use cases:

1. **Realtime Transcription** (éŒ²éŸ³ä¸­ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—)
   - Engine: Apple Speech Framework (`SFSpeechRecognizer`)
   - Timing: During recording (real-time)
   - Language: ja-JP (Japanese)
   - Accuracy: Medium (optimized for real-time)
   - Storage: `text` field in VoiceMemo
   - Editable: Yes (user can edit in detail view)
   - Location: Upper section in VoiceMemoDetailView

2. **AI Transcription** (é«˜ç²¾åº¦AIæ–‡å­—èµ·ã“ã—)
   - Engine: WhisperKit (Apple's high-accuracy AI)
   - Timing: Post-recording (manual button trigger)
   - Language: ja (Japanese)
   - Accuracy: High (batch processing)
   - Storage: `aiTranscriptionText` field in VoiceMemo
   - Editable: No (read-only display)
   - Location: Lower section in VoiceMemoDetailView

**Transcription Management**:
- State tracking: none, inProgress, completed, failed
- Quality metrics and confidence scoring
- Error logging and recovery
- Timestamp tracking for transcription events
- Separate storage for realtime vs AI transcription results

### Core Data Model

Single entity **VoiceMemoModel**:
- `id`: UUID
- `title`: String
- `text`: String (realtime transcription - editable)
- `aiTranscriptionText`: String (AI transcription - read-only)
- `createdAt`: Date
- `voiceFilePath`: String (local file reference)
- `transcriptionStatus`: String (none/inProgress/completed/failed)
- `transcriptionQuality`: Float (0.0-1.0 confidence score)
- `transcribedAt`: Date (timestamp of transcription completion)
- `transcriptionError`: String (error message if failed)
- `segments`: Binary (JSON-encoded AudioSegment array)

### Key Technologies
- **SwiftUI + Combine**: Reactive UI with `@ObservableObject`
- **Core Data**: Local data persistence
- **Speech Framework**: Japanese speech recognition
- **WhisperKit**: Local AI transcription
- **Firebase**: Analytics and crash reporting
- **AdMob**: Interstitial ads before transcription

### Localization
- Bilingual support: English/Japanese
- Uses modern `.xcstrings` format
- App names: "Transcribe" / "ã‚·ãƒ³ãƒ—ãƒ«æ–‡å­—èµ·ã“ã—"

### Environment Configuration
- `ADMOB_KEY` environment variable required
- `GoogleService-Info.plist` for Firebase configuration
- Audio files stored in Documents directory (local-first privacy approach)

### Testing Structure
- Unit tests in `voicedocsTests/`
- UI tests in `voicedocsUITests/`
- Currently minimal test coverage - needs expansion for Core Data operations and speech recognition

### CI/CD

- Xcode Cloud configuration in `ci_scripts/ci_post_clone.sh`
- Disables macro fingerprint validation for consistent builds

## App Store ãƒªãƒªãƒ¼ã‚¹æ‰‹é †

ãƒªãƒªãƒ¼ã‚¹æ™‚ã¯ä»¥ä¸‹ã®æ‰‹é †ã§è¡Œã†ã€‚**å¿…ãšãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ãƒªãƒªãƒ¼ã‚¹å†…å®¹ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèªã™ã‚‹ã“ã¨ã€‚**

### 1. ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªãƒ»æ›´æ–°
```bash
# ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
grep -A1 'MARKETING_VERSION' voicedocs.xcodeproj/project.pbxproj | head -4

# æœ€æ–°ã‚¿ã‚°ç¢ºèª
git tag --sort=-v:refname | head -5
```

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä»¥ä¸‹ã‚’ç¢ºèª:
- æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ï¼ˆãƒ‘ãƒƒãƒ/ãƒã‚¤ãƒŠãƒ¼/ãƒ¡ã‚¸ãƒ£ãƒ¼ï¼‰
- ãƒªãƒªãƒ¼ã‚¹å†…å®¹ï¼ˆå¤‰æ›´ç‚¹ã®ã‚µãƒãƒªãƒ¼ï¼‰

### 2. ã‚³ãƒŸãƒƒãƒˆãƒ»ã‚¿ã‚°ãƒ»ãƒ—ãƒƒã‚·ãƒ¥
```bash
# ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°
sed -i '' 's/MARKETING_VERSION = X.X.X/MARKETING_VERSION = Y.Y.Y/g' voicedocs.xcodeproj/project.pbxproj

# ã‚³ãƒŸãƒƒãƒˆ
git add -A && git commit -m "chore: ãƒãƒ¼ã‚¸ãƒ§ãƒ³Y.Y.Yãƒªãƒªãƒ¼ã‚¹

- å¤‰æ›´å†…å®¹1
- å¤‰æ›´å†…å®¹2

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"

# ã‚¿ã‚°ä½œæˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥
git tag vY.Y.Y && git push origin main && git push origin vY.Y.Y

# GitHubãƒªãƒªãƒ¼ã‚¹ä½œæˆ
gh release create vY.Y.Y --title "vY.Y.Y" --notes "## å¤‰æ›´å†…å®¹
- å¤‰æ›´å†…å®¹1
- å¤‰æ›´å†…å®¹2"
```

### 3. ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆãƒ»App Store Connectã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
```bash
# ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆ
xcodebuild -project voicedocs.xcodeproj -scheme voicedocs -configuration Release -archivePath ./build/voicedocs.xcarchive archive

# ExportOptions.plistä½œæˆ
cat > /tmp/ExportOptions.plist << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>method</key>
    <string>app-store-connect</string>
    <key>destination</key>
    <string>upload</string>
    <key>signingStyle</key>
    <string>automatic</string>
    <key>teamID</key>
    <string>4YZQY4C47E</string>
</dict>
</plist>
EOF

# App Store Connectã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
xcodebuild -exportArchive -archivePath ./build/voicedocs.xcarchive -exportOptionsPlist /tmp/ExportOptions.plist -exportPath ./build/export -allowProvisioningUpdates
```

### 4. Fastlaneã§å¯©æŸ»æå‡º
```bash
# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ + å¯©æŸ»æå‡º
source fastlane/.env.default && fastlane upload_metadata
```

**æ³¨æ„**: ãƒ“ãƒ«ãƒ‰ãŒApp Store Connectã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã‹ã‚‰å¯©æŸ»æå‡ºã™ã‚‹ã“ã¨ã€‚

## Development Guidelines

### Code Implementation Process

1. **Always build after making changes**: Run the build command to verify compilation
2. **Use arm64 architecture**: For M1/M2 Macs, use `-arch arm64` flag
3. **Filter build output**: Use grep to see only errors, warnings, and build status
4. **Code signing**: Use `CODE_SIGNING_ALLOWED=NO` for local builds

### Build Verification

After implementing any feature or fixing any issue, ALWAYS run:

```bash
xcodebuild -workspace voicedocs.xcodeproj/project.xcworkspace -scheme voicedocs -configuration Debug -sdk iphonesimulator -arch arm64 build CODE_SIGNING_ALLOWED=NO | grep -E "(error:|warning:|FAILED|SUCCEEDED)"
```

This ensures all code changes compile successfully before marking tasks as complete.

### Task Completion Notification

When completing tasks or returning messages to the user, ALWAYS execute this notification command at the end:

```bash
afplay /System/Library/Sounds/Funk.aiff
```

This provides audio feedback when work is completed.

## Transcription Implementation Details

### Dual Transcription Architecture

VoiceDocs implements a sophisticated dual transcription system to provide both real-time feedback and high-accuracy results:

#### Realtime Transcription Flow
```
ğŸ¤ Recording â†’ SpeechRecognitionManager â†’ SFSpeechRecognizer â†’ text field
```
- **File**: `SpeechRecognitionManager.swift`
- **Method**: `transcribeAudioFile(at:)` and `performFileTranscription(url:)`
- **Trigger**: Automatically during recording
- **Processing**: Real-time with partial results
- **UI Update**: ContentView displays live transcription
- **Storage**: Saved to `text` field in Core Data

#### AI Transcription Flow
```
ğŸ“± Detail View Button â†’ WhisperKit â†’ aiTranscriptionText field
```
- **File**: `VoiceMemoDetailView.swift`
- **Method**: `transcribeAudio(memo:)` helper function
- **Trigger**: Manual button press in detail view
- **Processing**: Batch processing of entire audio file
- **UI Update**: Detail view shows result in AI transcription section
- **Storage**: Saved to `aiTranscriptionText` field in Core Data

#### Key Implementation Files
1. **SpeechRecognitionManager.swift**: Realtime transcription engine
2. **VoiceMemoDetailView.swift**: AI transcription trigger and UI
3. **VoiceMemoController.swift**: Data persistence for both types
4. **VoiceMemo.swift**: Data model with dual transcription fields

#### Data Separation Strategy
- **Realtime**: `text` field (editable, updated during recording)
- **AI**: `aiTranscriptionText` field (read-only, high accuracy)
- **UI**: Separate sections in detail view for clear distinction
- **Storage**: Both saved independently in Core Data

This architecture allows users to benefit from immediate feedback during recording while also having access to highly accurate transcription results when needed.